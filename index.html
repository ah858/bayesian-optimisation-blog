<!DOCTYPE html>

<head>
	<title>Blog</title>
 	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="https://unpkg.com/tachyons@4.12.0/css/tachyons.min.css"/>
	<script src="https://d3js.org/d3.v6.js"></script>
	<!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/math/5.4.0/math.js"></script> -->
	<script src="https://unpkg.com/mathjs@8.0.1/lib/browser/math.js"></script>
	<!-- MathJax script import -->
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

	<link href="style.css" rel="stylesheet" type="text/css">
</head>

<body>
	<!-- Is the padding necessary here? Could have some nice block colors otherwise-->
<article class="pa3 pa3-ns">
	<!-- Header taken from: -->
	<!-- https://tachyons.io/components/articles/left-title-top-border/index.html  -->
	<!-- TODO: CSS magic to make it stack above text if device-width < threshold -->
	<header class="fn fl-ns w-50-ns pr4-ns">
		<h1 class="f2 lh-title fw9 mb3 mt0 pt3 bt bw2">
			Bayesian Optimization
		</h1>
		<h2 class="f3 mid-gray lh-title">
			a.h. &  b.m.
		</h2>
		<time class="f6 ttu tracked gray">Publication Date XX-01-2021</time>
	</header>

	<div class="cf">
		<div class="fl w-100 w-50-ns pv1 ph3 bl bw1">
		<!-- <div class="fl w-100 w-50-ns pv1 ph3 bb bw2 bg-lightest-blue" style="border-radius: 5px;"> -->
			<div>
			<!-- <div> -->
				<p>
					Bayesian Optimization is a powerful tool for automatic optimization of design choices. It has been used extensively in applications ranging from hyperparameter tuning for automatic machine learning to optimizing manufacturing and experiment design. We'll start off by introducing a typical, illustrative  problem setting for Bayesian Optimization, and show how the key components of Bayesian Optimization can automatise design decisions while significantly improving upon naive approaches.
				</p>
				<p>
					To-dos moved to: <a href="https://github.com/ah858/bayesian-optimisation-blog/projects/1">here</a>
				</p>
			</div>
		</div>
	</div>


	<div class="mw9 center ph3-ns">

		<!-- <div class="fl w-100 w-50-ns pv0 center"> -->
		<div class="cf">
			<div class="mw5 mw7-ns center mv4 pa3 ph5-ns">


				<h2>A Problem</h2>
				<p>
					Imagine you're on the engineering design team for a Formula One car. The team lead decided that redesigning the vehicle’s side wing may improve its cornering speed. A new shape has been proposed, however, the length of the side-wing, which can vary within the regulation constraints of 5cm - 40cm, is yet to be decided. Your job is to find the length of the wing that gives optimal performance as measured by the top cornering speed the driver is able to achieve.
				</p>

				<p>
					The challenge is that it is both expensive and slow to test new wing sizes. Each wing size prototype takes around a week to manufacture, install on the vehicle and get tested by the driver. There are only a few weeks left until the next Grand Prix, however, so you have limited time to find the best design.
				</p>
				<!-- !!Include something about hoping to automate the process as well. -->

		<!-- POSSIBLE FUNCTIONS -->

				<!-- <h3>Possible functions</h3> -->
				<p>
					This is a typical setting for Bayesian Optimization. In this scenario, we're trying to optimize an objective function \(f(x)\) - the vehicle's on track performance - as a function of the side-wing length \(x\). Unfortunately, we don't know what that function looks like: 
				</p>

				<!-- Posssible Functions Plot (inline) -->
		    	<div id="chart-possible-funcs"></div>
				<!-- <h2>Choosing points blindly</h2> -->
				<p>
					Since the objective function is expensive to evaluate - both in terms of time and manufacturing cost - we can only ever hope to observe the objective function at a limited number of points. Each evaluation is precious, we can't waste them.
				</p>

				<p>
					For these reasons, we need an efficient testing strategy. The tools of Bayesian Optimization are designed for situations like this.
				</p>

		        <p>
					Before we get on to how they work, however, try to have a go at picking the points yourself. There are 5 weeks left until the next race, so use the evaluations wisely:
				</p>

		    </div>
		</div>
		    

		<!-- BLIND CHOICE OF POINTS -->

		<div class="cf">
			<div class="mw8 center">
				<div class="fl w-100 w-70-ns pv0">
					<div id="chart-choose-points-blind"></div>
					</div>

				<div class="fl w-100 w-30-ns ph2 pv5">
					<p class="i f6">We'll pick a new underlying function for you on each reset. We wouldn't want to make it too easy.</p>
					<!-- <a class="f6 link dim br-pill ba ph3 pv1 dib black" href="#0">Play again</a> -->
				</div>
			</div>
		</div>

		<!-- MEAN ONLY CHOICE OF POINTS -->

		<div class="cf">
			<div class="mw5 mw7-ns center mv4 pa2 ph5-ns">
		    <!-- <div class="fl w-100 w-50-ns ph2 pv0"> -->
				<h2>Using a model</h2>

				<p>
					There are multiple ways to approach picking which points to evaluate. We could try naively picking the points at random, or divide the design-space uniformly and perform a grid-search. However, both of these approaches would be inefficient - they ignore the feedback which we sequentially receive from each experiment.
				</p>

				<p>
					To pick the next point, we want to utilise the information about which previously evaluated inputs turned out to be good, and which ones turned out to be bad. We want to focus our search on the most promising areas of the design space.
				</p>

				<p>
					Instead of just picking side-wing lengths blindly, one of the central ideas of Bayesian optimization is to use a <strong>model for the data</strong> to inform that choice. This would allow us to predict what vehicle's cornering speed - our objective - might be for wing lengths we haven't tested yet. This can give us a proxy for what the most promising regions to explore might be.
				</p>

				<p>
					By using a model, we could formulate an automated strategy: pick the side-wing that is predicted to give the highest expected cornering speed by the model.
				</p>

				<!-- Plot: Choose points using only the mean of model predictions -->
				<div id="chart-choose-points-with-mean"></div>

				<p>
					You might have noticed, however, that there is an evident issue with that selection strategy.
				</p>

		    </div> <!-- No vertical padding -->
		    <div class="fl w-100 w-50-ns">
		    	<!-- <div id="chart-choose-points-with-mean"></div> -->
		    </div>
		</div>

		<!-- EXPLAIN ISSUE WITH MEAN ALONE -->

		<div class="cf">
		    <div class="fl w-100 w-50-ns ph2 pv2">
		    	<h2>Explore vs exploit - the need for exploration</h2>
		    </div>
		</div>
 
		<div class="cf sticky-container" id="test-id"> <!-- ph2-ns -->
		    <div class="fl w-100 w-50-ns ph2 pv0">
				<div class="mb4">
					<p>
						Starting with the setup on the right, let's see what would happen if we strictly followed the <i>"pick the point with the best expected cornering speed predicted by the model"</i> strategy.
					</p>
				</div>
	<!-- 				<button id="button-explore-exploit-1">Pick naive point</button>
	 -->

		    	<div id="explore-exploit-text1" >
					<div id="explore-exploit-naive-point"></div> <!-- Use a div as the event trigger because it has 0 height. If the div had a non-zero height, the bounding box would cause assymetry in the scrolling down vs scrolling up IntersectionObserver calls. -->
					<div class="mt7 mb4">
						<p>
							In this case, by picking the best point predicted by the model, the chosen point ends up being really close to the previously tried designs that turned out fairly well.
						</p>
					</div>
				</div>
		    	<div id="explore-exploit-text2" >
					<div id="explore-exploit-show-true"></div>
					<div class="mt7 mb4">
						<p>
							While doing so, we are ignoring other unexplored parts of the search-space where an even better design is located. By applying this strategy repeatedly, we would only ever explore the one local optimum we've found so far, while ignoring a better optimum.
						</p>
						<!-- TODO: Highlight the word better optimum, and show a line on the chart -->
					</div>
				</div>

				<!-- TODO: This should pop into view separately, even though nothing happens on the plot -->
				<div class="mt6 mb4">
					<p>
						There is clearly a trade-off between selecting inputs close to the 'best' points observed so far (exploiting) and traversing the design-space in search of more prospective regions (exploring). This trade-off plays a central role in Bayesian Optimization.
					</p>
				</div>

				<div class="mt6 mb4">
			    	<!-- <h3>The need for a <i>probabilistic</i> model</h3> -->
					<p>
						As presented, there is a key missing component to our model that would allow us to explore effectively. Intuitively, we want to explore in areas where we believe there is a <strong>high probability</strong> that the design will be good. This can happen both in places where the model's mean prediction is high, or where the model's mean prediction is low, but the uncertainty in that prediction is high. Even though the expected value at a given point might be low, if the uncertainty is high enough, the probability of that point being by far the best one we've seen so far might actually be relatively large.
					</p>
				</div>
		    	<div id="explore-exploit-text3">
		    		<div id="explore-exploit-show-variance"></div>
					<p>
						To identify these high-risk high-reward regions, we need to be able to evaluate a notion of uncertainty in the model's predictions. We need a model that can give us a full predictive distribution over the possible values for the objective. A model for Bayesian Optimization ought to maintain a statistical picture of the function’s overall form given our observations of it.
					</p>
					<!-- TODO: I don't stand by the above statement (2nd to last sentence). -->
					<p>
						Hence, a key component of Bayesian Optimization is the use of a <strong>probabilistic</strong> model. Having access to the predictive distribution from such a model allows us to obtain the probability of each outcome, and consequently helps us identify good regions to explore.
					</p>
					<!-- The below sentence doesn't necessarily fit in there. It would go together with the whole paragraph on probabilistic models.-->
					<p>
						Gaussian Processes are one widely popular class of model for Bayesian Optimization of functions over continuous domains, like the one in this example. The formula for obtain the predictive distribution by marginalising out every possible hypothesis for the true function is analytical, and hence Gaussian Processes are great for obtaining reliable uncertainty estimates.</p>
					<p>
						To see what difference having the uncertainty estimates makes, give the optimization with a Gaussian Process model a go:
					</p>

				</div>
		    </div> <!-- No vertical padding -->
		    <div class="fl w-100 w-50-ns ph2 pv2 sticky">
		    	<div id="chart-explore-exploit"></div>
			</div>
		</div>


		<!-- MEAN and VARIANCE CHOICE OF POINTS -->
		<div class="cf mt6">
			<div class="mw5 mw7-ns center mv4 pa3 ph5-ns">
		    	<h2>Exploring uncertainty</h2>
				<div id="chart-choose-points-with-variance"></div>
			</div>
		</div>
		<div class="cf">
		<!-- Discussion of a decision rule -->
			<div class="mw5 mw7-ns center mv4 pa3 ph5-ns">
				<h2>Decision Rule</h2>
				<p>
					So far, we discussed the tension between exploration and exploitation and the motivation for using a probabilistic model as a key component of Bayesian Optimization to help balance the two. Since Bayesian Optimization is an <i>automatic</i> approach to making design choices, however, we're still clearly missing one component: a decision rule for picking the next point.
				</p>
				<h4>Acquisition Functions</h4>
				<!-- TODO: Good place for a: to find the maximum you need to find the maximum joke -->
				<p>
					Typically, to guide experiment selection in Bayesian Optimization approaches, one would define an acquisition function \(\alpha(x)\). Loosely speaking, the acquisition function characterises the expected utility of picking a particular point \(x\) as next input. The next \(x\) can then automatically be chosen as whichever one maximises the acquisition function: \(x_{\text{next}}=\arg \max_x \alpha(x)\)
				</p>
				<p>
					As an example, we can express the naive selection rule of "picking the point with the best expected cornering speed" with an acquisition function. We can define an acquisition function \(\alpha(x)\) that is equal to the expected predicted objective: \(\alpha(x) = \mathbb{E}_{y|x, \mathcal{D}}\left[y\right]\). By maximising this acquisition function, we would be picking the point with the highest predicted objective just as we did before:
				</p>
				<!-- TODO: Plot for simple acquisition function plot - alpha(x) = the predictive mean -->
				<p><strong>TODO:</strong> Plot showing the simple acquisition function</p>

				<p>
					We've seen the many short-coming of this acquisition function, which leads to the question: what is the right acquisition function? Starting from our goal of finding the best side-wing design, can we come up with an acquisition function that would lead us to the optimal rule for choosing an \(x\)? Let's try and do just that.
				</p>
				<p>
					<!-- TODO: Add a footnote saying that more general assumptions are possible (noise e.t.c.) -->
					Let's start by concretely formulating our problem. During the experimentation phase, we get to sequentially select \(N\) points \(x_i \in \mathbb{R}\), and observe the corresponding output \(y_i=f(x_i) \). At the end, after these trials are complete, we want to return a final recommendation for a design \(x^*\). Let's say that in our problem we assume that in the end we must return a design \(x^*\) from the set of wing lengths we've actually tested in the lab. On the race day, we require a tested design we have utmost confidence in. 
				</p>
				<!-- <p>
					 TODO: this quick note 
					<i style="opacity: 0.7; font-size: 11pt;">(It's possible to formulate the optimization problem in other ways, including observations with noise, returning a point \(x^*\) that hasn't been tested, or having a non-fixed number of steps left.) </i>
				</p> -->
				<p>
					Having defined our problem setup, let's also define our goal. We can define a utility function \(U(x^*)\) that characterise how good of our final design \(x^*\) is. Let's assume - for this problem - it is proportional to the achieved cornering speed \(y^* = f(x^*)\). In other words:
					\[U(x^*) = y^*\]
					To maximise this utility, we'd naturally want to report the best design we've found during our experimentation: \(y^* = \max \left(y_1, \dots, y_N\right)\).
				</p>
				<!-- TODO: add color to equations -->
				<p>
					To arrive at a general acquisition function, it helps to first imagine that we're at the end of the design period; we only have time to test one last prototype before we must pick a design to be manufactured for the race. So far, we have tried side-wing lengths \((x_1, .., x_{N-1})\), and observed corresponding speeds \((y_1, \dots, y_{N-1})\). Given this, the <i>extra</i> utility we get from evaluating the last point at \(x_N\), and observing a cornering speed \(y_N\) is:
				</p>
				\[\begin{align}
				\lambda &=\begin{cases}
					y_N - \max\left(y_1, \dots, y_{N-1}\right) & \text{if } y_N > \max\left(y_1, \dots, y_{N-1}\right) \\[.5em]
					0 & \text{if } y_N \leq \max\left(y_1, \dots, y_{N-1}\right)
				\end{cases} \\
				&=\max(y_N - \underbrace{\max\left(y_1, \dots, y_{N-1}\right)}_{\tau}, 0)
				\end{align}
				\]
				<!-- < start going side-by side again> -->
				<p>
					At the last step, we want to pick \(x_N\) to maximise this increase in utility. Of course, we don't know what the cornering speed \(y_N\) corresponding to the design \(x_N\) is going to be for sure, so we can maximise the <strong>expected improvement</strong> of the utility: 
				</p>
				\[\mathbb{E}_{y_N|x_N, \mathcal{D}} [\lambda] = \mathbb{E}_{y_N|x_N, \mathcal{D}} [\max(y_N - \tau, 0)]\]

				<p><strong>TODO:</strong> 1-step expected improvement visualisation</p>
				<p>
					<strong>TODO</strong>...
					So, in practice, a good acquisition function has to balance what's desirable from a theoretical point of view, with what's computationally tractable..
				</p>
			</div>
		</div>


		<!-- <div class="cf"> ph2-ns
		    <div class="fl w-100 w-50-ns ph2 pv0">
		    	<p>Picking the next point</p>

			</div>
			No vertical padding
		    <div class="fl w-100 w-50-ns">
		    	<div id="chart-choose-points-with-variance"></div>
		    </div>
		</div> -->


		<!-- SANDOX GAUSSIAN -->


		<div class="cf">
		    <div class="fl w-100 w-50-ns ph2 pv0">
		    	<h2>Later blog sections</h2>
		    </div>
		</div>

		<div class="cf"> <!-- ph2-ns -->
		    <div class="fl w-100 w-50-ns ph2 pv0"> <!-- No vertical padding -->
				<button id="button1">Expected improvement</button>
		    </div>
		    <div class="fl w-100 w-50-ns">
		    	<div id="chart-gp-sandox"></div>
		    </div>
		</div>


		<div class="cf"> <!-- ph2-ns -->
		    <div class="fl w-100 w-50-ns ph2 pv0"></div> <!-- No vertical padding -->
				<div id="chart-two-step"></div>
		    <div class="fl w-100 w-50-ns"></div>
		</div>


		<div class="cf"> <!-- ph2-ns -->
		    <div class="fl w-100 w-50-ns ph2 pv0"></div> <!-- No vertical padding -->
		    <div class="fl w-100 w-50-ns"></div>
		</div>

	</div>

	<script src="./js-refactored/shared-chart-parameters.js"></script>	
	<script src="./js-refactored/chart-possible-funcs.js"></script>
	<script src="./js-refactored/chart-choose-points-blind.js"></script>	
	<script src="./js-refactored/chart-choose-points-with-mean.js"></script>
	<script src="./js-refactored/chart-explore-exploit.js"></script>		
	<script src="./js-refactored/chart-choose-points-with-variance.js"></script>		
	<script src="./js-refactored/chart-gp-sandox.js"></script>		
	<script src="./js-refactored/chart-two-step.js"></script>
        
</article>


	<!-- <h1>Bayseian optimisation</h1>

	<div class="container">

		<div class="col">
			<p>This is the first text</p>

			<p>This is the second text</p>
		</div>div>

		<div class="col">

			<svg id="dataviz_area" height=200 width=450></svg>

		</div>div>

	</div> -->

</body>
