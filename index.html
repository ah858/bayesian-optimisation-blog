<!DOCTYPE html>

<head>
	<title>Blog</title>
 	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="https://unpkg.com/tachyons@4.12.0/css/tachyons.min.css"/>
	<script src="https://d3js.org/d3.v6.js"></script>
	<!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/math/5.4.0/math.js"></script> -->
	<script src="https://unpkg.com/mathjs@8.0.1/lib/browser/math.js"></script>
	<!-- MathJax script import -->
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

	<link href="style.css" rel="stylesheet" type="text/css">
</head>

<body>
	<!-- Is the padding necessary here? Could have some nice block colors otherwise-->
<article class="pa3 pa3-ns">
	<!-- Header taken from: -->
	<!-- https://tachyons.io/components/articles/left-title-top-border/index.html  -->
	<!-- TODO: CSS magic to make it stack above text if device-width < threshold -->
	<header class="fn fl-ns w-50-ns pr4-ns">
		<h1 class="f2 lh-title fw9 mb3 mt0 pt3 bt bw2">
			Bayesian Optimization
		</h1>
		<h2 class="f3 mid-gray lh-title">
			Akil Hashmi & Bruno Mlodozeniec
		</h2>
		<time class="f6 ttu tracked gray">Publication Date XX-XX-2021</time>
	</header>

	<div class="cf">
		<div class="fl w-100 w-50-ns pv1 ph3 bl bw1">
		<!-- <div class="fl w-100 w-50-ns pv1 ph3 bb bw2 bg-lightest-blue" style="border-radius: 5px;"> -->
			<div>
			<!-- <div> -->
				<p>
					<!-- We'll start off by introducing a typical, illustrative  problem setting for Bayesian Optimization, and show how the key components of Bayesian Optimization can automatise design decisions while significantly improving upon naive approaches.
					Bayesian Optimization is a principled framework for dealing with <i>design problems</i> – problems where we want to optimize for something in the face of uncertainty. It has been used extensively in practical optimization problems in the face of uncertainty: from hyperparameter tuning for automatic machine learning to optimizing manufacturing, or experiment design in synthetic biology.  We wanted to highlight how probabilistic reasoning (the "Bayesian" part of Bayesian Optimization) helps us to deal with the "uncertainty" bit, i.e. how it allows us to reason over the possible future observations to help us find a point close to the maximum the quickest. -->
				</p>
				<!-- <p>
					To-dos moved to: <a href="https://github.com/ah858/bayesian-optimisation-blog/projects/1">here</a>
				</p> -->
				<h2 class="f3 gray lh-title">
					Draft
				</h2>
			</div>
		</div>
	</div>


	<div class="mw9 center ph3-ns">

		<!-- <div class="fl w-100 w-50-ns pv0 center"> -->
		<div class="cf">
			<div class="mw5 mw7-ns center mv4 pa3 ph5-ns">


				<h2>A Problem</h2>
				<p>
					Imagine you're on the engineering design team for a Formula One car. The team lead decided that redesigning the vehicle’s front wing may improve its cornering speed. A new shape has been proposed, however, the length of the front-wing, which can vary within the regulation constraints of 5cm - 50cm, is yet to be decided. Your job is to find the length of the wing that gives optimal performance as measured by the cornering speed the driver is able to achieve.
				</p>

				<p>
					The challenge is: it is both expensive and slow to test new wing sizes. Each wing size prototype takes around a week to manufacture, install on the vehicle and get tested by the driver. There are only a few weeks left until the next Grand Prix, so you have limited time to find the best design.
				</p>
				<!-- !!Include something about hoping to automate the process as well. -->

		<!-- POSSIBLE FUNCTIONS -->

				<!-- <h3>Possible functions</h3> -->
				<p>
					This is a typical setting for Bayesian Optimization. In this problem, we're trying to optimize an objective function \(f(x)\) — the vehicle's on track performance — as a function of the front-wing length \(x\). Unfortunately, we don't know what that function looks like: 
				</p>

				<!-- Posssible Functions Plot (inline) -->
		    	<div id="chart-possible-funcs"></div>
				<!-- <h2>Choosing points blindly</h2> -->
				<p>
					Since the objective function is expensive to evaluate — both in terms of time and manufacturing cost — we can only ever hope to observe the objective function at a limited number of points. Each evaluation is precious, we can't waste them.
				</p>

				<p>
					For these reasons, we need an efficient testing strategy. The tools of Bayesian Optimization are designed to make optimal use of each of the tests in situations like this.
				</p>

		        <p>
					Before we get on to how they work, however, try to have a go at picking the points yourself. There are 5 weeks left until the next race – use the evaluations wisely:
				</p>

		    </div>
		</div>
		    

		<!-- BLIND CHOICE OF POINTS -->

		<div class="cf">
			<div class="mw8 center">
				<div class="fl w-100 w-70-ns pv0">
					<div id="chart-choose-points-blind"></div>
					</div>

				<div class="fl w-100 w-30-ns ph2 pv5">
					<p class="i f6">We'll pick a new underlying function for you on each reset. We wouldn't want to make it too easy.</p>
					<!-- <a class="f6 link dim br-pill ba ph3 pv1 dib black" href="#0">Play again</a> -->
				</div>
			</div>
		</div>

		<!-- MEAN ONLY CHOICE OF POINTS -->

		<div class="cf">
			<div class="mw5 mw7-ns center mv4 pa2 ph5-ns">
		    <!-- <div class="fl w-100 w-50-ns ph2 pv0"> -->
				<h2>Using a model</h2>

				<p>
					There are multiple ways to approach picking which points to evaluate. We could try naively picking the points at random, or divide the design-space uniformly into a grid. However, both of these approaches would be suboptimal – they ignore the feedback which we sequentially receive from each experiment.
				<!-- </p>

				<p> -->
					To pick the next point, we want to utilise the information about which previously evaluated inputs turned out to be good, and which ones turned out to be bad. We want to focus our search on the most promising areas of the design space.
				</p>

				<!-- TODO: Mention that the model is data dependent-->
				<p>
					Instead of just picking front-wing lengths to test blindly, one of the central ideas of Bayesian optimization is to use a <strong>model</strong> for the data to inform that decision. A model would allow us to make predictions for the vehicle's cornering speed for wing lengths we haven't tested yet. The predictions can be a good proxy for what the most promising regions to explore might be.
				</p>

				<p>
					By using a model, we could formulate an automated strategy. One such strategy might be: pick the front-wing that is predicted to give the highest expected cornering speed by the model.
				</p>

				<!-- Plot: Choose points using only the mean of model predictions -->
				<div id="chart-choose-points-with-mean"></div>

				<p>
					You might have noticed, however, that there is an evident issue with that selection strategy.
				</p>

		    </div> <!-- No vertical padding -->
		    <div class="fl w-100 w-50-ns">
		    	<!-- <div id="chart-choose-points-with-mean"></div> -->
		    </div>
		</div>

		<!-- EXPLAIN ISSUE WITH MEAN ALONE -->

		<div class="cf">
		    <div class="fl w-100 w-50-ns ph2 pv2">
		    	<h2>Explore vs exploit - the need for exploration</h2>
		    </div>
		</div>
 
		<div class="cf sticky-container" id="test-id"> <!-- ph2-ns -->
		    <div class="fl w-100 w-50-ns ph2 pv0">
				<div class="mb4">
					<p>
						Starting with the setup on the right, let's see what would happen if we strictly followed the <i>"pick the point with the best expected cornering speed predicted by the model"</i> strategy.
					</p>
				</div>
	<!-- 				<button id="button-explore-exploit-1">Pick naive point</button>
	 -->

		    	<div id="explore-exploit-text1" >
					<div id="explore-exploit-naive-point"></div> <!-- Use a div as the event trigger because it has 0 height. If the div had a non-zero height, the bounding box would cause assymetry in the scrolling down vs scrolling up IntersectionObserver calls. -->
					<div class="mt7 mb4">
						<p>
							In this case, by picking the best point predicted by the model, the chosen point ends up being really close to the previously tried designs that turned out fairly well.
						</p>
					</div>
				</div>
		    	<div id="explore-exploit-text2" >
					<div id="explore-exploit-show-true"></div>
					<div class="mt7 mb4">
						<p>
							While doing so, we are completely ignoring other unexplored parts of the search-space where an even better design could be located. By applying this strategy repeatedly, we would only ever explore the region around the one local optimum we've found so far. We'd never discover the better optimum in the unexplored region.
						</p>
						<!-- TODO: Highlight the word better optimum, and show a line on the chart -->
					</div>
				</div>

				<!-- TODO: This should pop into view separately, even though nothing happens on the plot -->
				<div class="mt6 mb4">
					<p>
						There is clearly a trade-off between selecting inputs close to the best points observed so far (exploiting) and traversing the design-space in search of more prospective regions (exploring). This trade-off plays a central role in Bayesian Optimization.
					</p>
				</div>

				<div class="mt6 mb4">
			    	<!-- <h3>The need for a <i>probabilistic</i> model</h3> -->
					<p>
						As presented, there is a key missing component to our model that would allow us decide where to explore. Intuitively, we want to explore areas where we believe there is a <strong>high probability</strong> that the design could improve significantly upon the best one found so far. This can happen both in places where the model's mean prediction is high, or where the model's mean prediction is lower, but the uncertainty in that prediction is high. Even though the <i>expected</i> value at a given point might be low, if we are uncertain enough, there could be a significant probability that that point might turn out to be the best one we've seen so far.
					</p>
				</div>
		    	<div id="explore-exploit-text3">
		    		<div id="explore-exploit-show-variance"></div>
					<p>
						To identify these high-risk high-reward regions we need to be able to evaluate a notion of uncertainty in each of model's predictions; we need a model that can give us a full predictive distribution over the possible values for the objective. A model for Bayesian Optimization ought to maintain a statistical picture of the function’s overall form given our observations of it.
					</p>
					<!-- TODO: I don't stand by the above statement (2nd to last sentence). -->
					<p>
						Hence, a key component of Bayesian Optimization is the use of a <strong>probabilistic</strong> model. A probabilistic model simply keeps track of all the possible objective functions, and weights them according to how likely they are given the data seen so far. Predictions from such a model tell us not only the most likely outcome for a given input, but also the probability of each other outcome as well, and consequently helps us identify good regions to explore.
					</p>
					<!-- The below sentence doesn't necessarily fit in there. It would go together with the whole paragraph on probabilistic models.-->
					<p>
						Gaussian Processes are one widely popular class of model for Bayesian Optimization of functions over <i>continuous</i> domains, like the one in this example. Weighing all the possible hypotheses to form a predictive distribution in Gaussian Processes can be done analytically, and hence Gaussian Processes are great for obtaining reliable uncertainty estimates.
					</p>
					<!-- TODO: is the 2nd sentence above really necessary-->
					<p>
						To see what difference having the uncertainty estimates makes, give the optimization with a Gaussian Process model a go:
					</p>

				</div>
		    </div> <!-- No vertical padding -->
		    <div class="fl w-100 w-50-ns ph2 pv2 sticky">
		    	<div id="chart-explore-exploit"></div>
			</div>
		</div>


		<!-- MEAN and VARIANCE CHOICE OF POINTS -->
		<div class="cf mt6">
			<div class="mw5 mw7-ns center mv4 pa3 ph5-ns">
		    	<h2>Exploring uncertainty</h2>
				<div id="chart-choose-points-with-variance"></div>
			</div>
		</div>
		<div class="cf">
		<!-- Discussion of a decision rule -->
			<div class="mw5 mw7-ns center mv4 pa3 ph5-ns">
				<h2>Decision Rule</h2>
				<p>
					So far, we discussed the tension between exploration and exploitation and the motivation for using a probabilistic model as a key component in Bayesian Optimization in order to help balance the two. Since Bayesian Optimization is an <i>automatic</i> approach to designing experiments, however, we're still clearly missing one component: a decision rule for selecting the next point.
				</p>
				<h4>Acquisition Functions</h4>
				<!-- TODO: Good place for a: to find the maximum you need to find the maximum joke -->
				<p>
					Typically, to guide experiment selection in Bayesian Optimization, one would define an <strong>acquisition function</strong> \(\alpha(x)\). In loose terms, the acquisition function would characterise how "good" a particular point \(x\) is as the next point to try out, i.e. how valuable it will be to observe the true objective in response to this input. If we had an expression for such an acquisition function, the next input \(x\) could then automatically be chosen as the input that maximises said acquisition function: \(x_{\text{next}}=\underset{x}{\operatorname{argmax}} \alpha(x)\). We could turn picking the next experiment into an optimization problem.
				</p>
				<p>
					This might seem a bit ironic: in order to solve an optimization problem <span class="gray">(finding the design maximising the objective \(x^*=\underset{x}{\operatorname{argmax}} f(x)\))</span> we introduced another one: maximising the acquisition function. The idea is that the acquisition function is (hopefully) much less expensive to evaluate than the true objective. In our Formula 1 example, evaluating the true objective necessitates manufacture of a component, which is time-consuming and monetarily costly. Evaluating the acquisition function requires only compute, and will hopefully be quick.
				</p>

				<p>
					As an example, an acquisition function can express the naive selection rule of "picking the point with the best expected cornering speed" – the naive strategy we suggested before. At each step \(i\), we can define an acquisition function \(\alpha_i(x_i)\) that is equal to the expected predicted objective:
				</p>
				<div class="cf">
					<div class="mw8 center">
						<div class="fl w-100 w-70-ns pv0">
							<p>

								\[\alpha_i(x_i) = \mathbb{E}_{y_i|x_i, \mathcal{D}_i}\left[y_i\right]\]

								By maximising this acquisition function, we would be picking the point with the highest predicted objective just as before:
							</p>
						</div>

						<div class="fl w-100 w-30-ns ph3">
							<p class="i f6 silver">\(\class{gray}{\mathcal{D}_i=\big((x_1, y_1),}\)\(\class{gray}{\dots, (x_{i-1}, y_{i-1})\big)}\) are the data-points collected prior to \(i\)-th step.</p>
							<!-- <a class="f6 link dim br-pill ba ph3 pv1 dib black" href="#0">Play again</a> -->
						</div>
					</div>
				</div>
				<!-- TODO: Plot for simple acquisition function plot - alpha(x) = the predictive mean -->
				<p><strong>TODO:</strong> Plot showing the simple acquisition function</p>
				<img src="expected-value-acquisition.png">

				<p>
					We've seen the short-comings of this acquisition, which leads to the question: what is the right acquisition function? Starting from the goal of finding the best front-wing design, can we come up with an acquisition function that would lead us to the optimal rule for choosing the next length \(x\) to test? Let's try and do just that.
				</p>
				<h3>Optimal Acquisition Function</h3>
				<p>
					We can start by concretely formulating our problem. During the experimentation phase, we get to sequentially select \(N\) inputs \(x_i \in \mathbb{R}\), and observe the corresponding output \(y_i=f(x_i) \). At the end, after these trials are complete, we want to return a final recommendation for the optimal front-wing length \(x^*\). We'll assume that we <i>have to</i> recommend a design \(x^*\) from the set of wing lengths that were tested in the lab <a class="gold link dim collapsible-button footnote-button" href="#0"></a>. On the race day, we require a tested design we have utmost confidence in. 
				</p>
				<div class="collapsible-content footnote-content ph3 center gold bl bw2">
					It's possible to formulate the optimization problem in other ways, including observations with noise, returning a point \(x^*\) that hasn't been tested, or having a non-fixed number of steps left.
				</div>
				<p>
					Having defined our problem setup, let's also be precise about our goal. We can define a utility function \(U(x^*)\) that quantifies how good the final design is. Let's assume — for this problem — it is proportional to the cornering speed \(y^* = f(x^*)\). In other words:
					\[U(x^*) = y^* = f(x^*)\]
					To maximise this utility, we'd naturally want to report the best design we've found during our experimentation:
					\[x^*_{\text{final}} = x_{\class{light-red}{i^*}}\quad\text{ where }\class{light-red}{i^*}=\underset{i\in \{1,\dots, N\}}{\operatorname{argmax}} y_i\]

					To arrive at a general acquisition function, it helps to first consider the specific case when we're almost at the end of the design period; we only have time to test one last prototype before we must pick a design to be manufactured for the race. So far, we have tried front-wing lengths \((x_1, \dots, x_{N-1})\) and observed corresponding speeds \((y_1, \dots, y_{N-1})\). Given these, we can define the <i>extra</i> utility we would get from evaluating the last point at \(x_N\), and (hypothetically) observing a cornering speed \(y_N\):
				</p>
				\[\begin{align}
				\lambda_N &=\begin{cases}
					\class{light-purple}{y_N - \max\left(y_1, \dots, y_{N-1}\right)} & \class{dark-pink}{\text{if } y_N > \max\left(y_1, \dots, y_{N-1}\right)} \\[.5em]
					\class{black}{0} & \class{blue}{\text{if } y_N \leq \max\left(y_1, \dots, y_{N-1}\right)}
				\end{cases} \\
				&=\max(\class{light-purple}{y_N - \max\left(y_1, \dots, y_{N-1}\right)}, \class{black}{0})
				\end{align}
				\]
				<p>
					Let's break this down. <span class="dark-pink">If the output \(y_N\) is <strong>better</strong> than the best design seen in the previous \(N - 1\) steps, \(x_N\) will be returned as the optimal design.</span> The extra gain in utility of the final design will be \(\class{light-purple}{ y_N - \max (y_1, \dots, y_{N-1})}\). </span> <span class="blue">If the output \(y_N\) is not better than that of previous designs, the extra utility will be \(\class{black}{0}\), as one of the previous \(N-1\) designs will be returned.</span>
				</p>
				<!-- < start going side-by side again> -->
				<p>
					We want to pick \(x_N\) as to maximise this increase in utility. Of course, <i>a-priori</i>, we don't know what the cornering speed \(y_N\) corresponding to a given design length \(x_N\) is going to be. Instead, we can maximise the <strong>expected improvement</strong> in the utility: 
				</p>
				\[\mathbb{E}_{y_N|x_N, \mathcal{D}_N} [\lambda_N] = \mathbb{E}_{y_N|x_N, \mathcal{D}_N} [\max(y_N - \max\left(y_1, \dots, y_{N-1}\right), 0)]\]
				<p>
					That is, we want to maximise the extra utility from observing \((x_N, y_N)\) averaged over the probability density of obtaining a particular output \(y_N\) in response to input \(x_N\). The formula for the expected improvement above then becomes our <i>optimal</i> acquisition function in the \(N\)-th step:
					\[\alpha_N(x_N)=\mathbb{E}_{y_N|x_N, \mathcal{D}_N} [\lambda_N]\]
				</p>
				<p>
					We visualize this <strong>1-step</strong> expected improvement below:
				</p>

				<p><strong>TODO:</strong> 1-step expected improvement visualisation</p>
				<img src="1step-expected-improvement.png">
				<p>
					This acquisition function is also relatively easy to compute. We just need to take an expectation of a rather simple function<a class="gold link dim collapsible-button footnote-button" href="#0"></a> with respect to \(y_N\) conditioned on the data we've seen so far. We can either use <a class="dark-blue link dim" href="https://en.wikipedia.org/wiki/Monte_Carlo_method#Overview">Monte-Carlo sampling</a>, or in the case where the predictive distribution is a Gaussian distribution, a simple <a class="link">exact formula</a> exists <a class="gold link dim collapsible-button footnote-button" href="#0"></a>.
				</p>
				<div class="collapsible-content footnote-content ph3 center gold bl bw2">
					The "simple" function of \(y_N\). It's essentially like a shifted <a class="dark-blue link dim" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">ReLU</a> function.
					<img src="truncated_linear.svg">
				</div>
				<div class="collapsible-content footnote-content ph3 center gold bl bw2">
					If the predictive distribution is a Gaussian – <span class="gray">\(p(y_N|x_N, \mathcal{D}_N)=\mathcal{N}(y_N; \mu, \sigma)\)</span> – then the 1-step expected improvement is:

					<div class="gray scrollable-mathjax">
					\[\max(\mu - y_{max}, 0)+\sigma \varphi\left(\frac{\mu - y_{max}}{\sigma}\right)-\left|\mu - y_{max}\right| \Phi\left(\frac{\mu - y_{max}}{\sigma}\right)\]
					</div>
					where \(\varphi(\cdot)\) is the standard normal probability density function and \(\Phi(\cdot)\) is the respective cumulative distribution function. 

					See <a class="link light-blue dim" href="https://arxiv.org/pdf/1807.02811.pdf">"A Tutorial on Bayesian Optimization" by Peter I. Frazier</a> for details.
				</div>

				<h4>Optimal Acquisition Function with 2 steps left</h4>
				<p>
					What's then the optimal point to pick when there are \(2\) steps left? In a similar way, we can think about the expected extra utility in the steps <i>following</i> hypothetically picking a particular input \(x_{N-1}\) and observing some output \(y_{N-1}\). The contributions to this extra utility will come from two places. Firstly, from the immediate improvement from the output observed at step \(N-1\):
				</p>
				\[\lambda_{N-1}\overset{\small \operatorname{def}}{=}\max(y_{N - 1} - \max (y_1, \dots, y_{N-2}), 0)\]
				<p>
					And, secondly, from the (1-step) <strong>expected</strong> improvement at step \(N\) (expected, since the outcome \(y_N\) is unknown):

						\[\mathbb{E}_{y_{N} \mid x_{N}, \mathcal{D}_{N}}\left[\lambda_{N}\right]\]
				</p>
				<p>
					We'll assume that after the current \((N-1)\)-th step, we will <span class="red">pick the last input \(x_N\) optimally</span> (why wouldn't we?) by maximising this expected improvement in the last step. Then, the total expected improvement from step \(N-1\) onwards (after observing a particular pair \((x_{N-1}, y_{N-1})\)) becomes:
				</p>
				\[
					\underbrace{\lambda_{N-1}}_{\text{improvement in step }N-1} + \underbrace{\class{red}{\max_{x_N'}} \overbrace{\mathbb{E}_{y_N|\class{red}{x_N'}, \mathcal{D}_N} \left[\lambda_N\right]}^{\text{(1-step) expected improvement in step }N}}_{\text{optimal expected improvement in step }N} \\
				\]
				<p>
					Of course, at the point of picking \(x_{N-1}\), we again do not know the value of \(y_{N-1}\). To obtain the best possible outcome in expectation, we average out all the possibilities to arrive at the optimal acquistion function at step \(N-1\):
				</p>
					\[
				\begin{align}
					\alpha_{N-1}(x_{N-1})=&\mathbb{E}_{y_{N-1}|x_{N-1}, \mathcal{D}_{N-1}}\left[\lambda_{N-1} + {\max_{x_N'}}\ \mathbb{E}_{y_N|{x_N'}, \mathcal{D}_N} \left[\lambda_N\right] \right]\\
					=& \class{green}{\mathbb{E}_{y_{N-1}|x_{N-1}, \mathcal{D}_{N-1}} \left[ \lambda_{N-1}\right]} + \class{blue}{\mathbb{E}_{y_{N-1}|x_{N-1}, \mathcal{D}_{N-1}}\left[\max_{x_N'} \mathbb{E}_{y_N|{x_N'}, \mathcal{D}_N} \left[\lambda_N \right]\right]}
				\end{align}
					\]
				<a class="collapsible-button light-blue link dim bl bw2 ph3" href="#0">Math Legend</a>
				<div class="collapsible-content light-blue bl bw2 ph3">
					<p class="gray f6">Notation is ready to forget on a first read, so here are some helpers:</p>
					<ul class="list pl0">
						<li>
							\(\class{blue}{\lambda_i}\) - improvement in the maximimum observed objective at step \(i\): \(\max \left(y_{i}-\max \left(y_{1}, \ldots, y_{i-1}\right), 0\right)\)
						</li>
						<li>
							\(\class{blue}{\mathbb{E}_{y_{i} \mid x_{i}, \mathcal{D}_{i}}\left[\cdot\right]}\) - expectation with respect to the predicted output \(y_{i}\) at input \(x_{i}\) conditioned on all the data observed at step \(i\).
						</li>
						<li>
							\(\class{blue}{\mathcal{D}_i}\) - data observed at step \(i\): \(\big((x_1, y_1), \dots, (x_{i-1}, y_{i-1})\big)\)
						</li>
					</ul>
				</div>
				<p>
					Again, we arrived at an acqusition function that will give us the optimal decision when there are \(2\) steps remaining. This expression naturally decomposes into the sum of the <span class="green">immediate (1-step) expected improvement</span>, and the <span class="blue">expectation of the expected improvement in the next step</span>. By optimizing the <span class="green">first term</span>, we are trying to pick a point that is likely to improve the most upon the current best. By optimizing the <span class="blue">second term</span>, we are picking a point that will provide most useful information about the function in order to make the largest possible improvement in the step that follows. The \(2\)-step expected improvement balances the first <i>myopic</i> goal with the second far-sighted one.
				</p>
				<p>
					The second term — the <span class="blue">expectation of the expected improvement in the next step</span> — warrants a closer look to get some intuition for it.
				</p>
				\[
				\begin{align}
				&\class{blue}{\mathbb{E}_{y_{N-1} \mid x_{N-1}, \mathcal{D}_{N-1}}\Big[\max_{x_{N}^{\prime}} \mathbb{E}_{y_{N} \mid x_{N}^{\prime}, \mathcal{D}_{N}}\left[\lambda_{N}\right]\Big]}=\\
				=&
				\underbrace{\int_{y_{N-1}\in \mathbb{R}}}_{1.}
				\underbrace{\left(\max_{x_{N}^{\prime}} \mathbb{E}_{y_{N} \mid x_{N}^{\prime}, \mathcal{D}_{N}}\left[\lambda_{N}\right]\right)}_{2.}
				\underbrace{p\left(y_{N-1}|x_{N-1}, \mathcal{D}_{N-1}\right)
				dy_{N-1}}_{3.}
				\end{align}
				\]
				<p>
					This term says:
					<ul class="list pl3">
						<li class="mv1">
							\(1.\) Consider every possible value that the output \(y_{N-1}\) could hypothetically take in response to \(x_{N-1}\).
						</li>
						<li class="mv1">
							\(2.\) For each of those values calculate the <i>best</i> 1-step expected improvement in the next step.
						</li>
						<li class="mv1">
							\(3.\) Average those best 1-step expected improvements weighted by the probability of the hypothetical observations \(y_{N-1}\).
						</li>
					</ul>

					We can visualise this acquisition broken down in this way: 
				</p>
				<p>
					<strong>TODO: Only keep the top plot</strong>
				</p>
				<div class="cf"> <!-- ph2-ns -->
					<div class="fl w-100 w-50-ns ph2 pv0"></div> <!-- No vertical padding -->
						<div id="chart-two-step"></div>
					<div class="fl w-100 w-50-ns"></div>
				</div>
		
				<p>
					The plot above shows (on the bottom axis) the \(2\)-step expected improvement broken down into the two components. The <span class="green">green part</span> of the curve {match equation to plot or plot to equation} shows the <span class="green">immediate \(1\)-step expected improvement</span>. The top part shows the <span class="blue">expected improvement in the next step</span>. 
					This part is further sub-divided into contributions corresponding to each hypothetical observation of \(y_{N-1}\) at the current step. Each sub-part is equal to the <i>best achievable</i> expected improvement in the next step conditioned on a particular observation of \(y_{N-1}\) (hover over the plot to see which one), weighted by the probability of observing this particular value of \(y_{N-1}\)<a class="gold link dim collapsible-button footnote-button" href="#0"></a>. The plot also shows, for each hypothetical observation \(y_{N-1}\), the optimal input \(x_N\) that would be chosen at the next step.
				</p>
				<div class="collapsible-content footnote-content ph3 center gold bl bw2">
					<p>
					To make this figure, we approximate the predictive distribution (which, in the figure, is a Gaussian) for \(y_{N-1}\) conditioned on \(x_{N-1}, \mathcal{D}_{N-1}\) with a discrete distribution.
					We do this, because it would have been impossible to make this figure if we considered every possible hypothetical value for \(y_{N-1}\), since \(y_{N-1}\) is continuous.
					We chose to discretise the distribution for \(y_{N-1}\) at \(5\) locations: at the mean, at the mean \(\pm 1\) standard deviation, and at the mean \(\pm 2\) standard deviations.
					</p>
					<p>
					If you are particularly curious about the approximation, here are some more technical details: the probabilities for each of the \(5\) outcomes are assigned to be the closest possible match to the true predictive distribution, in the sense that the approximate distribution \(q\) minimises the KL-divergence to the true distribution \(p\):
					\[q=\underset{q^\prime}{\operatorname{argmin}} KL[q^\prime||p]\]

					This can done by making the weights be proportional to the probability density function of the true distribution at these locations (such that they still sum to \(1\)).
					</p>
				</div>
				<h4>Computational Tractability</h4>
				<p>
					This acquisition is, however, already strikingly harder to compute numerically compared to the \(1-step\) expected improvement. No analytical solution is known even when the model's predictions are of a simple form (such as a Gaussian). To see clearly why, let's look at what we need to compute. We saw that the <span class="green">first term</span> is just the \(1\)-step expected improvement, which is quite simple to compute; there ia a closed-form solution when \(y_{N-1}|x_{N-1}, \mathcal{D}_{N-1}\) is Gaussian-distributed. Hence, let's look closer at the <span color="blue">second</span> term and how to compute it, since that's the troublesome one:
				</p>
				\[\underbrace{\class{blue}{\mathbb{E}_{y_{N-1} \mid x_{N-1}, \mathcal{D}_{N-1}}\Big[}\underbrace{\class{blue}{\max_{x_{N}^{\prime}}} \overbrace{\class{blue}{\mathbb{E}_{y_{N} \mid x_{N}^{\prime}, \mathcal{D}_{N}}\left[\lambda_{N}\right]}}^{\text{I}}}_{\text{II}}\class{blue}{\Big]}}_{\text{III}}\]

				Here are the steps necessary to compute this quantity for a particular value of \(x_{N-1}\):
				<ul class="list pl1">
					<li class="mv1">
						\(\text{I}\). This inner part is just a 1-step expected improvement. As mentioned before, this term is relatively simple to compute for any particular \(x^\prime_{N}\).
					</li>
					<li class="mv1">
						\(\text{II}\). To compute this expression we need to (numerically) optimize the 1-step expected improvement expression from step \(\text{I}\) to find its maximum. This computation is equivalent to finding the maximum of the optimal acqusition function at the \(N\)-th step of the Bayesian Optimization procedure. Now, however, we need to perform this computation just to evaluate the optimal acquisition function at one point.
					</li>
					<li class="mv1">
						\(\text{III}\). To compute this term we need to take the expectation of the quantity in \(\text{II}\). One obvious way to approximate this is to sample \(y_{N-1}|x_{N-1}, \mathcal{D}_{N-1}\) and average \(\text{II}\) over the drawn samples. The quantity \(\text{II}\) needs to be recomputed for every sample. Since computing this quantity was an optimization problem, this is rather computationally burdensome. In addition, there is also the overhead of updating the model with each hypothetical observation \(y_{N-1}\) before computing that quantity.
					</li>
				</ul>
				<p>
				    It's hopefully clear that this is computationally a pretty hard task. Well, ok, we did actually compute this \(2\)-step optimal acquisition function to make the interactive plot above, which (hopefully) runs in your browser. It's just-about tractable on this one-dimensional problem. Going beyond \(2\) steps, e.g. to compute \(3\)-step or \(4\)-step optimal acquisition functions gets intractable really fast though.
				</p>
				<h3>What actually makes a good acquistion function</h3>
				<p>
					On this note, we could continue this blog in a similar way to derive optimal acqusitions for when there are \(3\) steps left, \(4\) steps left, and so forth. These expressions will get exponentially harder and harder to compute, to the point where we wouldn't be able to use them in any practical problem, or plot them to get intuition for how they work.
				</p>
				<p>
					So, in practice, a good acquisition function has to balance what's desirable from a theoretical point of view, with what's computationally tractable. Actually using the optimal acquisition function is rarely possible (except for the very last \(1\) or \(2\) steps of the optimization problem).
				</p>
				<p>
					One common option is to use the acquisition function that's optimal for the last step — the \(1\)-step expected improvement — but at every step of the process. This obviously has downsides – an acquisition that at every step assumes it's the last step is unlikely to pick more "explorative" points that might be useful in the long run. On the other hand, it's computationally a very efficient approach.
				</p>
				<p>
					For these reasons, many other acquisition functions and various ways to approximate them have been proposed in the literature. Some are motivated in other ways than the "decision-theoretic" motivation outlined in this blog. For instance, some are motivated from an information-theoretic perspective (e.g. <a class="link dark-blue dim" href="https://jmlr.csail.mit.edu/papers/volume13/hennig12a/hennig12a.pdf">ES</a>, <a class="link dark-blue dim" href="https://arxiv.org/abs/1406.2541">PES</a>, <a class="link dark-blue dim" href="https://arxiv.org/abs/1703.01968">MES</a>), whilst other are being argued for on the basis of their <i>asymptotic</i> optimality (e.g. <a class="link dark-blue dim" href="https://arxiv.org/abs/1206.6457">UCB</a>). Yet other researcher will try to develop acquisitions for more specialised scenarios: for instance, some try to tackle the case when data is collected in batches rather a single example at a time, whilst others might consider the case when observations arrive asynchronously. The range of trade-offs considered and extensions to the Bayesian Optimization framework is broad. If you need convincing (or just want to see what's out there), this timeless survey paper — <a class="dark-blue link dim" href="https://ieeexplore.ieee.org/document/7352306">Taking the Human Out of the Loop</a> — does a great job of covering <i>a lot</i>.
				</p>
				<p>
					The goal of this blog was really to get at the core of what Bayesian Optimization is: an automated approach to tackling <i>design problems</i> – problems where we want to optimize for something in the face of uncertainty. We wanted to highlight how probabilistic reasoning (the "Bayesian" part of Bayesian Optimization) helps us to deal with the "uncertainty" bit, i.e. how it allows us to reason over the possible future observations to help us find a point close to the maximum the quickest.
				</p>
			</div>
		</div>


		<!-- <div class="cf"> ph2-ns
		    <div class="fl w-100 w-50-ns ph2 pv0">
		    	<p>Picking the next point</p>

			</div>
			No vertical padding
		    <div class="fl w-100 w-50-ns">
		    	<div id="chart-choose-points-with-variance"></div>
		    </div>
		</div> -->


		<!-- SANDOX GAUSSIAN -->

		<!-- MEAN and VARIANCE CHOICE OF POINTS -->
		<div class="cf mt6">
			<div class="mw5 mw7-ns center mv4 pa3 ph5-ns">
		    	<h2>Later blog sections</h2>
			</div>
			<p><strong>TODO: Delete?</strong> I think none of these are necessarily still relevant</p>
		</div>

		<div class="cf">
			<div class="mw8 center">

				<div class="fl w-100 w-50-ns ph2 pv0"> <!-- No vertical padding -->
					<button id="button1">Expected improvement</button>
				</div>
				<div class="fl w-100 w-50-ns">
					<div id="chart-gp-sandox"></div>
				</div>


				<div class="cf"> <!-- ph2-ns -->
					<div class="fl w-100 w-50-ns ph2 pv0"></div> <!-- No vertical padding -->
						<div id="chart-two-step-monte-carlo"></div>
					<div class="fl w-100 w-50-ns"></div>
				</div>



			</div>
		</div>



<!-- 
		<div class="cf">
		    <div class="fl w-100 w-50-ns ph2 pv0">
		    	<h2>Later blog sections</h2>
		    </div>
		</div>

		<div class="cf"> <!-- ph2-ns ->
		    <div class="fl w-100 w-50-ns ph2 pv0"> <!-- No vertical padding ->
				<button id="button1">Expected improvement</button>
		    </div>
		    <div class="fl w-100 w-50-ns">
		    	<div id="chart-gp-sandox"></div>
		    </div>
		</div>


		<div class="cf"> <!-- ph2-ns ->
		    <div class="fl w-100 w-50-ns ph2 pv0"></div> <!-- No vertical padding ->
				<div id="chart-two-step"></div>
		    <div class="fl w-100 w-50-ns"></div>
		</div>

		<div class="cf"> <!-- ph2-ns ->
		    <div class="fl w-100 w-50-ns ph2 pv0"></div> <!-- No vertical padding ->
				<div id="chart-two-step-monte-carlo"></div>
		    <div class="fl w-100 w-50-ns"></div>
		</div>


		<div class="cf"> <!-- ph2-ns ->
		    <div class="fl w-100 w-50-ns ph2 pv0"></div> <!-- No vertical padding ->
		    <div class="fl w-100 w-50-ns"></div>
		</div> -->

	</div>

	<script src="./js-refactored/shared-chart-parameters.js"></script>	
	<script src="./js-refactored/chart-possible-funcs.js"></script>
	<script src="./js-refactored/chart-choose-points-blind.js"></script>	
	<script src="./js-refactored/chart-choose-points-with-mean.js"></script>
	<script src="./js-refactored/chart-explore-exploit.js"></script>		
	<script src="./js-refactored/chart-choose-points-with-variance.js"></script>		
	<script src="./js-refactored/chart-gp-sandox.js"></script>		
	<script src="./js-refactored/chart-two-step.js"></script>
	<script src="./js-refactored/chart-two-step-monte-carlo.js"></script>
	<script src="./js-refactored/collapsible-footnote.js"></script>
        
</article>


	<!-- <h1>Bayseian optimisation</h1>

	<div class="container">

		<div class="col">
			<p>This is the first text</p>

			<p>This is the second text</p>
		</div>div>

		<div class="col">

			<svg id="dataviz_area" height=200 width=450></svg>

		</div>div>

	</div> -->

</body>
